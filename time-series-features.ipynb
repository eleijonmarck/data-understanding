{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "from scipy import stats\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "\n",
    "def zero_empty(arg):\n",
    "    if type(arg) == np.ndarray and arg.size > 0:\n",
    "        return arg\n",
    "    elif arg.size > 0:\n",
    "        return arg\n",
    "    else:\n",
    "        return np.array([0, 0])\n",
    "    \n",
    "def classic_sta_lta(x, length_sta, length_lta):\n",
    "    \n",
    "    sta = np.cumsum(x ** 2)\n",
    "\n",
    "    # Convert to float\n",
    "    sta = np.require(sta, dtype=np.float)\n",
    "\n",
    "    # Copy for LTA\n",
    "    lta = sta.copy()\n",
    "\n",
    "    # Compute the STA and the LTA\n",
    "    sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n",
    "    sta /= length_sta\n",
    "    lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n",
    "    lta /= length_lta\n",
    "\n",
    "    # Pad zeros\n",
    "    sta[:length_lta - 1] = 0\n",
    "\n",
    "    # Avoid division by zero by setting zero values to tiny float\n",
    "    dtiny = np.finfo(0.0).tiny\n",
    "    idx = lta < dtiny\n",
    "    lta[idx] = dtiny\n",
    "\n",
    "    return sta / lta\n",
    "\n",
    "def gp_features(iterable, index):\n",
    "    features = pd.DataFrame(index=index, dtype=np.float32)\n",
    "    \n",
    "    peak_heights = [10, 20, 50, 100]\n",
    "\n",
    "    for segment, sample in enumerate(iterable):\n",
    "        \n",
    "        peaks = signal.find_peaks(sample,\n",
    "                                  height=(100, 1000000),\n",
    "                                  distance=100)\n",
    "        \n",
    "        \n",
    "        \n",
    "        features.loc[segment, \"num_peaks\"] = len(peaks[0])\n",
    "        features.loc[segment, \"max_peak_h\"] = max(zero_empty(peaks[1][\"peak_heights\"]))\n",
    "        features.loc[segment, \"min_peak_h\"] = min(zero_empty(peaks[1][\"peak_heights\"]))\n",
    "        features.loc[segment, \"mean_peak_h\"] = np.mean(zero_empty(peaks[1][\"peak_heights\"]))\n",
    "        features.loc[segment, \"std_peak_h\"] = np.std(zero_empty(peaks[1][\"peak_heights\"]))\n",
    "        \n",
    "        features.loc[segment, \"max_peak_p\"] = max(zero_empty(peaks[0]))\n",
    "        features.loc[segment, \"min_peak_p\"] = min(zero_empty(peaks[0]))\n",
    "        features.loc[segment, \"mean_peak_p\"] = np.mean(zero_empty(peaks[0]))\n",
    "        features.loc[segment, \"std_peak_p\"] = np.std(zero_empty(peaks[0]))\n",
    "        features.loc[segment, \"peak_max_diff\"] = max(zero_empty(np.diff(zero_empty(peaks[0]))))\n",
    "        features.loc[segment, \"peak_min_diff\"] = min(zero_empty(np.diff(zero_empty(peaks[0]))))\n",
    "        features.loc[segment, \"peak_avg_diff\"] = np.mean(zero_empty(np.diff(zero_empty(peaks[0]))))\n",
    "        features.loc[segment, \"peak_std_diff\"] = np.std(zero_empty(np.diff(zero_empty(peaks[0]))))\n",
    "        \n",
    "        x = pd.Series(sample)\n",
    "        \n",
    "        features.loc[segment, 'mean'] = x.mean()\n",
    "        features.loc[segment, 'std'] = x.std()\n",
    "        features.loc[segment, 'max'] = x.max()\n",
    "        features.loc[segment, 'min'] = x.min()\n",
    "\n",
    "        features.loc[segment, 'mean_change_abs'] = np.mean(np.diff(x))\n",
    "        features.loc[segment, 'abs_max'] = np.abs(x).max()\n",
    "        features.loc[segment, 'abs_min'] = np.abs(x).min()\n",
    "\n",
    "        features.loc[segment, 'std_first_50000'] = x[:50000].std()\n",
    "        features.loc[segment, 'std_last_50000'] = x[-50000:].std()\n",
    "        features.loc[segment, 'std_first_10000'] = x[:10000].std()\n",
    "        features.loc[segment, 'std_last_10000'] = x[-10000:].std()\n",
    "\n",
    "        features.loc[segment, 'avg_first_50000'] = x[:50000].mean()\n",
    "        features.loc[segment, 'avg_last_50000'] = x[-50000:].mean()\n",
    "        features.loc[segment, 'avg_first_10000'] = x[:10000].mean()\n",
    "        features.loc[segment, 'avg_last_10000'] = x[-10000:].mean()\n",
    "\n",
    "        features.loc[segment, 'min_first_50000'] = x[:50000].min()\n",
    "        features.loc[segment, 'min_last_50000'] = x[-50000:].min()\n",
    "        features.loc[segment, 'min_first_10000'] = x[:10000].min()\n",
    "        features.loc[segment, 'min_last_10000'] = x[-10000:].min()\n",
    "\n",
    "        features.loc[segment, 'max_first_50000'] = x[:50000].max()\n",
    "        features.loc[segment, 'max_last_50000'] = x[-50000:].max()\n",
    "        features.loc[segment, 'max_first_10000'] = x[:10000].max()\n",
    "        features.loc[segment, 'max_last_10000'] = x[-10000:].max()\n",
    "        \n",
    "        features.loc[segment, 'q95'] = np.quantile(x, 0.95)\n",
    "        features.loc[segment, 'q99'] = np.quantile(x, 0.99)\n",
    "        features.loc[segment, 'q05'] = np.quantile(x, 0.05)\n",
    "        features.loc[segment, 'q01'] = np.quantile(x, 0.01)\n",
    "\n",
    "        features.loc[segment, 'abs_q95'] = np.quantile(np.abs(x), 0.95)\n",
    "        features.loc[segment, 'abs_q99'] = np.quantile(np.abs(x), 0.99)\n",
    "        features.loc[segment, 'abs_q05'] = np.quantile(np.abs(x), 0.05)\n",
    "        features.loc[segment, 'abs_q01'] = np.quantile(np.abs(x), 0.01)\n",
    "        \n",
    "        features.loc[segment, 'mad'] = x.mad()\n",
    "        features.loc[segment, 'kurt'] = x.kurtosis()\n",
    "        features.loc[segment, 'skew'] = x.skew()\n",
    "        features.loc[segment, 'med'] = x.median()\n",
    "        \n",
    "        \n",
    "        features.loc[segment, 'Hilbert_mean'] = np.abs(hilbert(x)).mean()\n",
    "        features.loc[segment, 'Hann_window_mean'] = (convolve(x, hann(150), mode='same') / sum(hann(150))).mean()\n",
    "        features.loc[segment, 'classic_sta_lta1_mean'] = classic_sta_lta(x, 500, 10000).mean()\n",
    "        features.loc[segment, 'classic_sta_lta2_mean'] = classic_sta_lta(x, 5000, 100000).mean()\n",
    "        features.loc[segment, 'classic_sta_lta3_mean'] = classic_sta_lta(x, 3333, 6666).mean()\n",
    "        features.loc[segment, 'classic_sta_lta4_mean'] = classic_sta_lta(x, 10000, 25000).mean()\n",
    "        features.loc[segment, 'classic_sta_lta5_mean'] = classic_sta_lta(x, 50, 1000).mean()\n",
    "        features.loc[segment, 'classic_sta_lta6_mean'] = classic_sta_lta(x, 100, 5000).mean()\n",
    "        features.loc[segment, 'classic_sta_lta7_mean'] = classic_sta_lta(x, 333, 666).mean()\n",
    "        features.loc[segment, 'classic_sta_lta8_mean'] = classic_sta_lta(x, 4000, 10000).mean()\n",
    "        features.loc[segment, 'Moving_average_700_mean'] = x.rolling(window=700).mean().mean(skipna=True)\n",
    "        ewma = pd.Series.ewm\n",
    "        features.loc[segment, 'exp_Moving_average_300_mean'] = (ewma(x, span=300).mean()).mean(skipna=True)\n",
    "        features.loc[segment, 'exp_Moving_average_3000_mean'] = ewma(x, span=3000).mean().mean(skipna=True)\n",
    "        features.loc[segment, 'exp_Moving_average_30000_mean'] = ewma(x, span=30000).mean().mean(skipna=True)\n",
    "        no_of_std = 3\n",
    "        features.loc[segment, 'MA_700MA_std_mean'] = x.rolling(window=700).std().mean()\n",
    "        features.loc[segment,'MA_700MA_BB_high_mean'] = (features.loc[segment, 'Moving_average_700_mean'] + no_of_std * features.loc[segment, 'MA_700MA_std_mean']).mean()\n",
    "        features.loc[segment,'MA_700MA_BB_low_mean'] = (features.loc[segment, 'Moving_average_700_mean'] - no_of_std * features.loc[segment, 'MA_700MA_std_mean']).mean()\n",
    "        features.loc[segment, 'MA_400MA_std_mean'] = x.rolling(window=400).std().mean()\n",
    "        features.loc[segment,'MA_400MA_BB_high_mean'] = (features.loc[segment, 'Moving_average_700_mean'] + no_of_std * features.loc[segment, 'MA_400MA_std_mean']).mean()\n",
    "        features.loc[segment,'MA_400MA_BB_low_mean'] = (features.loc[segment, 'Moving_average_700_mean'] - no_of_std * features.loc[segment, 'MA_400MA_std_mean']).mean()\n",
    "        features.loc[segment, 'MA_1000MA_std_mean'] = x.rolling(window=1000).std().mean()\n",
    "        features.drop('Moving_average_700_mean', axis=1, inplace=True)\n",
    "\n",
    "        features.loc[segment, 'iqr'] = np.subtract(*np.percentile(x, [75, 25]))\n",
    "        features.loc[segment, 'q999'] = np.quantile(x,0.999)\n",
    "        features.loc[segment, 'q001'] = np.quantile(x,0.001)\n",
    "        features.loc[segment, 'ave10'] = stats.trim_mean(x, 0.1)\n",
    "        \n",
    "        for windows in [10, 100, 1000, 10000]:\n",
    "            rolls = [\n",
    "                (\"x_roll_std\", x.rolling(windows).std().dropna().values),\n",
    "                (\"x_roll_mean\", x.rolling(windows).mean().dropna().values),\n",
    "                (\"x_roll_sum\", x.rolling(windows).sum().dropna().values),\n",
    "                (\"x_roll_std_std\", x.rolling(windows).std().rolling(windows).std().dropna().values),\n",
    "                (\"x_roll_mean_std\", x.rolling(windows).mean().rolling(windows).std().dropna().values),\n",
    "                (\"x_roll_std_mean\", x.rolling(windows).std().rolling(windows).mean().dropna().values),\n",
    "                (\"x_roll_mean_mean\", x.rolling(windows).mean().rolling(windows).mean().dropna().values),\n",
    "                (\"x_roll_quantile50\", x.rolling(windows).quantile(0.5).dropna().values),\n",
    "                (\"x_roll_quantile05\", x.rolling(windows).quantile(0.05).dropna().values),\n",
    "                (\"x_roll_quantile90\", x.rolling(windows).quantile(0.90).dropna().values)\n",
    "            ]\n",
    "            \n",
    "            for name, roll in rolls:\n",
    "            \n",
    "                features.loc[segment, 'ave_%s_%s' % (name, str(windows))] = roll.mean()\n",
    "                features.loc[segment, 'std_%s_%s' % (name, str(windows))] = roll.std()\n",
    "                features.loc[segment, 'max_%s_%s' % (name, str(windows))] = roll.max()\n",
    "                features.loc[segment, 'min_%s_%s' % (name, str(windows))] = roll.min()\n",
    "                features.loc[segment, 'q01_%s_%s' % (name, str(windows))] = np.quantile(roll, 0.01)\n",
    "                features.loc[segment, 'q05_%s_%s' % (name, str(windows))] = np.quantile(roll, 0.05)\n",
    "                features.loc[segment, 'q25_%s_%s' % (name, str(windows))] = np.quantile(roll, 0.25)\n",
    "                features.loc[segment, 'q50_%s_%s' % (name, str(windows))] = np.quantile(roll, 0.50)\n",
    "                features.loc[segment, 'q75_%s_%s' % (name, str(windows))] = np.quantile(roll, 0.75)\n",
    "                features.loc[segment, 'q95_%s_%s' % (name, str(windows))] = np.quantile(roll, 0.95)\n",
    "                features.loc[segment, 'q99_%s_%s' % (name, str(windows))] = np.quantile(roll, 0.99)\n",
    "                features.loc[segment, 'median_%s_%s' % (name, str(windows))] = np.median(roll)\n",
    "                features.loc[segment, 'av_change_abs_%s_%s' % (name, str(windows))] = np.mean(np.diff(roll))\n",
    "                features.loc[segment, 'av_change_rate_%s_%s' % (name, str(windows))] = np.mean(np.nonzero((np.diff(roll) / roll[:-1]))[0])\n",
    "                features.loc[segment, 'abs_max_%s_%s' % (name, str(windows))] = np.abs(roll).max()\n",
    "               \n",
    "        \n",
    "        \n",
    "        features.loc[segment, 'autocorr'] = feature_calculators.autocorrelation(x, 100)\n",
    "        \n",
    "        cent, var, skew, kurt = feature_calculators.fft_aggregated(x, [\n",
    "            {\n",
    "                \"aggtype\": \"centroid\"\n",
    "            },\n",
    "            {\n",
    "                \"aggtype\": \"variance\"\n",
    "            },\n",
    "            {\n",
    "                \"aggtype\": \"skew\"\n",
    "            },\n",
    "            {\n",
    "                \"aggtype\": \"kurtosis\"\n",
    "            },\n",
    "        ])\n",
    "        \n",
    "        features.loc[segment, 'eig_cent'] = cent[1]\n",
    "        features.loc[segment, 'eig_var'] = var[1]\n",
    "        features.loc[segment, 'eig_skew'] = skew[1]\n",
    "        features.loc[segment, 'eig_kurt'] = kurt[1]\n",
    "        \n",
    "        x.name = \"hello\"\n",
    "        \n",
    "        pv, rv, intr, sl, stdr = feature_calculators.linear_trend(x, [{\"attr\": \"pvalue\"}\n",
    "                                                  ,{\"attr\": \"rvalue\"}\n",
    "                                                  ,{\"attr\": \"intercept\"}\n",
    "                                                  ,{\"attr\": \"slope\"}\n",
    "                                                  ,{\"attr\": \"stderr\"}])\n",
    "        \n",
    "        features.loc[segment, 'lin_pv'] = pv[1]\n",
    "        features.loc[segment, 'lin_var'] = rv[1]\n",
    "        features.loc[segment, 'lin_intr'] = intr[1]\n",
    "        features.loc[segment, 'lin_sl'] = sl[1]\n",
    "        features.loc[segment, 'lin_stdr'] = stdr[1]\n",
    "        \n",
    "        features.loc[segment, 'count_above_mean'] = feature_calculators.count_above_mean(x)\n",
    "        features.loc[segment, 'count_below_mean'] = feature_calculators.count_below_mean(x)\n",
    "        \n",
    "        for peak in peak_heights:\n",
    "            features.loc[segment, (\"num_peaks_%s\" % peak)] = feature_calculators.number_peaks(x, peak)\n",
    "            \n",
    "            \n",
    "        for peak in peak_heights:\n",
    "            peaks = signal.find_peaks(sample,\n",
    "                              height=(-peak * 10, -peak),\n",
    "                              distance=40)\n",
    "            \n",
    "            \n",
    "            features.loc[segment, \"neg_num_peaks_%s\" % peak] = len(peaks[0])\n",
    "            features.loc[segment, \"neg_max_peak_h_%s\" % peak] = max(zero_empty(peaks[1][\"peak_heights\"]))\n",
    "            features.loc[segment, \"neg_min_peak_h_%s\" % peak] = min(zero_empty(peaks[1][\"peak_heights\"]))\n",
    "            features.loc[segment, \"neg_mean_peak_h_%s\" % peak] = np.mean(zero_empty(peaks[1][\"peak_heights\"]))\n",
    "            features.loc[segment, \"neg_std_peak_h_%s\" % peak] = np.std(zero_empty(peaks[1][\"peak_heights\"]))\n",
    "\n",
    "            features.loc[segment, \"neg_max_peak_p_%s\" % peak] = max(zero_empty(peaks[0]))\n",
    "            features.loc[segment, \"neg_min_peak_p_%s\" % peak] = min(zero_empty(peaks[0]))\n",
    "            features.loc[segment, \"neg_mean_peak_p_%s\" % peak] = np.mean(zero_empty(peaks[0]))\n",
    "            features.loc[segment, \"neg_std_peak_p_%s\" % peak] = np.std(zero_empty(peaks[0]))\n",
    "            features.loc[segment, \"neg_peak_max_diff_%s\" % peak] = max(zero_empty(np.diff(zero_empty(peaks[0]))))\n",
    "            features.loc[segment, \"neg_peak_min_diff_%s\" % peak] = min(zero_empty(np.diff(zero_empty(peaks[0]))))\n",
    "            features.loc[segment, \"neg_peak_avg_diff_%s\" % peak] = np.mean(zero_empty(np.diff(zero_empty(peaks[0]))))\n",
    "            features.loc[segment, \"neg_peak_std_diff_%s\" % peak] = np.std(zero_empty(np.diff(zero_empty(peaks[0]))))\n",
    "        \n",
    "        print(\"Progress: %s / %s\" % (segment, len(iterable)), end = \"             \\r\")\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
